### 浏览器的结构

- 用户界面 - 包括地址栏、前进/后退按钮、书签菜单等。
- 用户界面后端 - 用于绘制基本的窗口小部件，比如组合框和窗口。
- 浏览器引擎 - 在用户界面和呈现引擎之间传送指令。
- 渲染引擎（rendering engine） - 渲染内容，主要是html,css,图片等。dsfsdf
- JavaScript 解释器。用于解析和执行 JavaScript 代码。
- 网络 - 用于网络调用，比如 HTTP 请求。
- 数据存储。这是持久层。浏览器需要在硬盘上保存各种数据，例如 Cookie。













### 渲染引擎

渲染引擎分两种，firfox是Gecko，这是 Mozilla 公司“自制”的。而`Safari`和`Chrome`浏览器使用的都是 `WebKit`



## 流程

一开始会从网络层获取请求文档的内容，内容的大小一般限制在 8000 个块以内。

然后进行如下所示的基本流程：

![](http://p8cyzbt5x.bkt.clouddn.com/UC20180619_195129.png)

渲染引擎解析 HTML 文档，将各个dom标签逐个转化成“content tree”上的 DOM 节点。同时也会解析内部和外部的css, 解析为`css tree`, `css tree`和`dom tree`结合在一起生成了`render tree`

`render tree`是由一系列在按照顺序排列起来的方块组成的，每一个方块都包含类似于颜色、尺寸的信息。

在`render tree`构建好之后，渲染引擎就会经历一个`layout`的阶段: 计算出每一个节点应该出现在屏幕上的确切坐标。

之后的阶段被称为`paiting`阶段，渲染引擎会遍历`render tree`, 然后由用户界面后端层将每一个节点绘制出来。

渲染引擎会尽快把内容呈现在屏幕上，因此不会等待整个文档加载之后才开始构建，而是一边加载一部分，渲染引擎一边渲染一部分。

![webkit 渲染引擎的主流程](http://p8cyzbt5x.bkt.clouddn.com/UC20180619_200256.png)

下面，我们针对浏览器上面的环节，逐一的介绍一下：

## 第一步：解析

解析是渲染引擎中非常重要的一个环节。我们现在先不管html解析、css解析之类的。我们先大致了解一下解析到底是怎么一回事。

### 一般性的解析

通俗来讲，解析文档是指将**文档转化成为有意义的结构，好让代码去使用他们**。

![](http://p8cyzbt5x.bkt.clouddn.com/UC20180704_145218.png)

解析可以分为两大块，一块是**vocabulary**，另一块是**syntax rules**。

以上面图中为例， `1 + 2 * 3` 的代码中，**valcabulary** 包括`1`、`2`、`3`，除此之外，`+` 、`*` 等运算符也属于valcabulary。 

**syntax rules**主要是规定了valcabulary 之间是如何相互组合的，比如说，`+` 可以放在数字的左边，也可以放在数字的后面，`*` 的运算优先级要比 `+` 更高。

上面的图，右边就是解析好的树状结构，这个结构就可以“喂“给其他的程序, 然后其他的程序就可以利用这个结构，生成一些计算的结果。



解析的过程可以分成两个子过程：**lexical analysis(词法分析)**和**syntax analysis(句法分析)**。

#### **lexical analysis(词法分析)**

**lexical analysis**的过程，有的文章也称为 **tokenization**，其实就是把输入的内容分为不同的**tokens**(不知道怎么翻译，国内有博客翻译为标记)，tokens是最小的组成部分，tokens就像是人类语言中的一堆词汇。比如说，我们对一句英文进行lexical analysis——“The quick brown fox jumps”，我们可以拿到以下的token:

- “The”
- “quick”
- “brown”
- “fox”
- “jumps”

那么用来做lexical analysis的工具，被称为**`lexer`**， 它负责把输入的内容分为不同的tokens。不同的浏览器会选择不同的lexer , 比如说webkit 是使用Flex 作为lexer。



#### syntax analysis(句法分析)

**syntax analysis**是应用语言句法中的规则， 简单来说，就是判断一串tokens组成的句子是不是正确的。

如果我说：“我吃饭工作完了”， 这句话是不符合syntax analysis的，虽然里面的每一个token都是正确的，但是不符合语法规范。需要注意的是，符合语法正确 的句子不一定是符合语义正确的。比如说，“一个绿色的梦想沉沉的睡去了”，从语法的角度来讲，形容词 + 主语 + 副词 + 动词没有问题，但是语义上却是什么鬼。

负责`syntax analysis`工作的是**`parser`**，解析是一个不断往返的过程。

如下图所示，`parser`向`lexer`要一个新的`token`，`lexer`会返回一个`token`, `parser`拿到`token`之后，会尝试将这个`token`与某条语法规则进行匹配。

![](http://p8cyzbt5x.bkt.clouddn.com/UC20180704_151126.png)

如果该`token`匹配上了语法规则，`parser`会将一个对应的节点添加到 parse tree （解析树，如果是html就是dom树，如果是css就是 cssom tree）中，然后继续问parser要下一个node。

当然，也有可能该`tokens`没有匹配上语法规则，`parser`会将`tokens`暂时保存，然后继续问`lexer`要`tokens`, 直至找到可与所有内部存储的标记匹配的规则。如果找不到任何匹配规则，`parser`就会引发一个异常。这意味着文档无效，包含语法错误。

`syntax analysis` 的输出结果是parse tree ( 这里不是dom tree, 也不是 cssom tree , 因为我们这里讨论的是普遍性一般性的解析 ) , parse tree 的结构表示了句法结构。比如说我们输入"John hit the ball"作为一句话，那么 `syntax analysis` 的结果就是：

![](http://p8cyzbt5x.bkt.clouddn.com/UC20180704_165209.png)

一旦我们拿到了`parse tree`， 还有最后一步工作没有做，那就是：`translation`，还有一些博客将这个过程成为 compilation / transpilation / interpretation 

你拿到了 parse tree, 你就有了你所要的所有信息。

#### **Lexicons and Syntaxes**

lexicons 是通过正则表达式被定义的，比如说，js中的保留字，就是lexicons 的一部分。

下面就是js中的保留字的正则表达式 的一部分。

```
/^(?!(?:do|if|in|for|let|new|try|var|case|else|enum|eval|false|null|this|true|void|with|break|catch|class|const|super|throw|while|yield|delete|export|import|public|return|static|switch|typeof|default|extends|finally|package|private|continue|debugger|function|arguments|interface|protected|implements|instanceof)$)*$/
```

`syntaxes` 通常是被一个叫**无上下文语法**所定义，关于**无上下文语法**可以点击这个[链接](https://en.wikipedia.org/wiki/Context-free_grammar)（因为我也看不懂哈哈），反正只需要知道，无上下文语法要比常规的语法更复杂就好了。

那为什么我们要介绍`lexicons` 和 `syntaxes` 呢？

上面提到的`lexer` 和 `parser` 这两个解析工具，我们通常不会自己写，而是用现有的工具去生成。我们只需要提供一个语言的 `lexicon` 和 `syntaxes` ，就可以自动生成相应的 `lexer` 和 `parser` 了。

webkit 就是用这样两种工具**：Flex**  和 **Bison**

`flex` 和`css` 的 `flex` 布局没有关系，是 `fast-lexer` 的简写，用来生成 `lexer`。 它需要一个`lexicon`，这个`lexicon` 是用一堆正则表达式来定义的 。

bison 用来生成**parsers,**  它需要一个符合**BNF范式**的syntax。 

非科班出身的前端可能不了解 BNF 范式（说的就是我 --），它是一种形式化符号来描述给定语言的语法。

它的内容大致为：

1. 在双引号中的字("word")代表着这些字符本身。
2. 而double_quote用来代表双引号。
3. 在双引号外的字（有可能有下划线）代表着语法部分。
4. 尖括号( < > )内包含的为必选项。
5. 方括号( [ ] )内包含的为可选项。
6. 大括号( { } )内包含的为可重复0至无数次的项。
7. 竖线( | )表示在其左右两边任选一项，相当于"OR"的意思。
8. ::= 是“被定义为”的意思。



下面是用BNF来定义的Java语言中的For语句的实例。

```
FOR_STATEMENT ::=
"for" "(" ( variable_declaration |
( expression ";" ) | ";" )
[ expression ] ";"
[ expression ]
")" statement
```



> BNF 的诞生还是挺有意思的一件事情， 有了BNF才有了真正意义上的计算机语言。巴科斯范式直到今天，仍然是个迷，巴科斯是如何想到的



我们现在对解析过程有了一个大致的了解，总结成一张图就是这样：

![](http://p8cyzbt5x.bkt.clouddn.com/UC20180704_204630.png)



接下来，我们专门讨论一下HTML的解析过程。

### HTML 的解析过程

html 是不规范的，我们在写html的代码时候，比如说漏了一个闭合标签，浏览器也可以正常渲染没有问题的。这是一把双刃剑，我们可以很容易的编写html, 但是却给html的解析带来不少的麻烦，更详细的信息可以点击：[链接](https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/#HTML_Parser)

#### lexicon

Html 的 lexicon 主要包括6个部分：、

- doctype
- start tag
- end tag
- comment
- character
- End-of-file

当一个html文档被lexer 处理的时候，lexer 从文档中一个字符一个字符的读出来，并且使用 finite-state machine 来判断一个完整的token是否已经被完整的收到了。

#### syntax

这里就是html 解析的复杂所在了。html 标签的容错性很高，需要上下文敏感的语法。

比如说对于下面两段代码：

```html
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>Valid HTML</title>
  </head>
  <body>
    <p>This is a paragraph. <span>This is a span.</span></p>
    <div>This is a div.</div>
  </body>
</html>
```

```html
<html lAnG = EN-US>
<p>This is a paragraph. <span>This is a span. <div>This is a div.
```

第一段是规范的html代码，第二段代码有非常多的错误，但是这两段代码在浏览器中都是大致相同的结构：

![](http://p8cyzbt5x.bkt.clouddn.com/UC20180704_211329.png)

上面两处代码渲染出来的唯一的不同就是，正确的html会在头部有`<!DOCTYPE html>`,  这行代码会触发浏览器的标准模式。

所以你看，html 的容错性是非常高的，这样是有代价的，这增加了解析的困难，让词法解析解析更加困难。

#### DOM tree

HTML 解析出来的 parse html 并不是严格意义上的DOM tree。为了在浏览器里面用， Dom tree 是对解析出来的 parse tree做了进一步的加工。

对于下面这种html的结构：

```html
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    <meta name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1">
  </head>
  <body>
    <p>
      This is text in a paragraph.
      <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/14/Rubber_Duck_%288374802487%29.jpg/220px-Rubber_Duck_%288374802487%29.jpg">
    </p>
    <div>
      This is text in a div.
    </div>
  </body>
</html>
```

上面的html 的结构解析出来应该是：

![](http://p8cyzbt5x.bkt.clouddn.com/UC20180704_211037.png)



说完了html的解析，我们就该说CSS的解析了。

### CSS 解析

和html 解析相比，css 的解析就简单很多了。 

#### lexicon

关于css的 `lexicon`， [the W3C’s CSS2 Level 2 spec](https://www.w3.org/TR/CSS2/syndata.html#tokenization)ification 中已经给出了。

CSS 中的 token 被列在了下面，下面的定义是采用了`Lex`风格的正则表达式。

```
IDENT	{ident}
ATKEYWORD	@{ident}
STRING	{string}
BAD_STRING	{badstring}
BAD_URI	{baduri}
BAD_COMMENT	{badcomment}
HASH	#{name}
NUMBER	{num}
PERCENTAGE	{num}%
DIMENSION	{num}{ident}
URI	url\({w}{string}{w}\)
|url\({w}([!#$%&*-\[\]-~]|{nonascii}|{escape})*{w}\)
UNICODE-RANGE	u\+[0-9a-f?]{1,6}(-[0-9a-f]{1,6})?
CDO	<!--
CDC	-->
:	:
;	;
{	\{
}	\}
(	\(
)	\)
[	\[
]	\]
S	[ \t\r\n\f]+
COMMENT	\/\*[^*]*\*+([^/*][^*]*\*+)*\/
FUNCTION	{ident}\(
INCLUDES	~=
DASHMATCH	|=
DELIM	any other character not matched by the above rules, and neither a single nor a double quote
```

花括号里面的宏被定义成如下：

```
ident	[-]?{nmstart}{nmchar}*
name	{nmchar}+
nmstart	[_a-z]|{nonascii}|{escape}
nonascii	[^\0-\237]
unicode	\\[0-9a-f]{1,6}(\r\n|[ \n\r\t\f])?
escape	{unicode}|\\[^\n\r\f0-9a-f]
nmchar	[_a-z0-9-]|{nonascii}|{escape}
num	[0-9]+|[0-9]*\.[0-9]+
string	{string1}|{string2}
string1	\"([^\n\r\f\\"]|\\{nl}|{escape})*\"
string2	\'([^\n\r\f\\']|\\{nl}|{escape})*\'
badstring	{badstring1}|{badstring2}
badstring1	\"([^\n\r\f\\"]|\\{nl}|{escape})*\\?
badstring2	\'([^\n\r\f\\']|\\{nl}|{escape})*\\?
badcomment	{badcomment1}|{badcomment2}
badcomment1	\/\*[^*]*\*+([^/*][^*]*\*+)*
badcomment2	\/\*[^*]*(\*+[^/*][^*]*)*
baduri	{baduri1}|{baduri2}|{baduri3}
baduri1	url\({w}([!#$%&*-~]|{nonascii}|{escape})*{w}
baduri2	url\({w}{string}{w}
baduri3	url\({w}{badstring}
nl	\n|\r\n|\r|\f
w	[ \t\r\n\f]*
```

#### Syntax

下面是css的 syntax 定义：

```
stylesheet  : [ CDO | CDC | S | statement ]*;
statement   : ruleset | at-rule;
at-rule     : ATKEYWORD S* any* [ block | ';' S* ];
block       : '{' S* [ any | block | ATKEYWORD S* | ';' S* ]* '}' S*;
ruleset     : selector? '{' S* declaration? [ ';' S* declaration? ]* '}' S*;
selector    : any+;
declaration : property S* ':' S* value;
property    : IDENT;
value       : [ any | block | ATKEYWORD S* ]+;
any         : [ IDENT | NUMBER | PERCENTAGE | DIMENSION | STRING
              | DELIM | URI | HASH | UNICODE-RANGE | INCLUDES
              | DASHMATCH | ':' | FUNCTION S* [any|unused]* ')'
              | '(' S* [any|unused]* ')' | '[' S* [any|unused]* ']'
              ] S*;
unused      : block | ATKEYWORD S* | ';' S* | CDO S* | CDC S*;
```



















浏览器中的解析分为两种，一种是conventional parser , 一种是 unconventional parser。css 和 javascript的解析是通过 conventional parser，而html的解析是通过 unconventional parser。为什么会有这样的区别，我们下面来解释。

![截图来自Kruno: How browsers work | JSUnconf 2017的演讲](http://p8cyzbt5x.bkt.clouddn.com/UC20180704_144703.png)



### unconventional parser







#### render tree

一边构建dom tree, 一边生成render tree。 这两个是同时进行的。

render tree是可以被展示的那些元素，按照被展示的顺序排列起来。render tree 上面的元素被称为 `renderer`, 或者 被称为 `render objects`, 不同的浏览器叫法不同。需要注意的是，`render objects` 都长方形。



#### layout




